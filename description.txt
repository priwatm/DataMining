                    Программа TextAnalyzer: общее описание.

    Программа TextAnalyzer для извлечения ключевых понятий из текста написана на языке программирования python [1] c использованием графического редактора кода Spyder [2] и интерактивной (браузерной) консоли Jupyter Notebook [3]. Python интерпретатор, описанные утилиты, а также базовый набор python-пакетов (библиотек) доступен в python-сборке Anaconda [4]. Для реализации программы был также использован использован дополнительный python-пакет pymorphy2 [5], работающий с открытым словарем OpenCorpora [6] (по данной ссылке также доступны расшифровки обозначений для морфологических характеристик слов, используемые в pymorphy2). Данный модуль осуществляет морфологический анализ лексем (слов) и позволяет, в частности, получить нормальную форму слова, часть речи, падеж, проверить, является ли данная лексема аббревиатурой, именем/отчеством/фамилией и т.д. Также (при наличии соединения Интернет) программа может использовать Яндекс-API для поиска синонимов заданного слова.

    Программный код в папке text_analyzer реализован в файлах:
1) dictionary.py - содержит класс Dictionary, хранящий заданные пользователем словари,
2) grammar.py - содержит класс Grammar, хранящий заданные пользователем правила грамматического соответствия слов,
3) entity.py - содержит класс Entity, описывающий сущность,
4) link.py - содержит класс Link, описывающий связи между сущностями,
5) text_analyzer.py - содержит класс TextAnalyzer, предоставляющий интерфейс для анализа заданного текста,
6) __init__.py - пустой файл, являющийся индикатором пакета (соглашение в языке python),
7) файлы с расширением .pyc - транслированные в бинарный код модули - файлы программы (трансляция в языке python происходит автоматически при первом обращении к модулю).

    Тестирование программы производится с использованием интерактивной консоли Jupyter Notebook - файл ta_example.ipynb. Для запуска анализатора необходимо:
1) Импортировать рабочие модули: 
    from text_analyzer.grammar import Grammar
    from text_analyzer.dictionary import Dictionary
    from text_analyzer.text_analyzer import TextAnalyzer
2) Создать экземпляр класса 
    Dict = Dictionary()
указать параметры сетового соединения для использования Яндекс-API для поиска синонимов:
    Dict.set_syn_api(use_syn_api=True, syns_max_lvl=2)
переменная syns_max_lvl обозначает число итераций поиска синонимов (для указанного значения 2 для каждого слова будет производиться поиск синонимов, а затем для каждого из найденных синонимов вновь будет произведен подобный поиск, а затем все полученные списки будут объединены). Затем следует задать словари. Словарь может задаваться двумя способами:
2.1) С помощью перечисления словарных слов, соответствующих данному словарю: 
    Dict.add(u'ПРЕДМЕТ', words=[u'машина', u'квартира'])
здесь мы создаем новый словарь с именем 'ПРЕДМЕТ', содержащий всего два слова (в нормальной форме) 'машина' и 'квартира'.
2.2) Вместо задания слов указать правило, по которому слово может быть причислено к данному словарю, например:
    Dict.add(u'ФАМИЛИЯ', lambda E: True if 'Surn' in E.wtag else False)
здесь мы указываем, что сущность (E) принадлежит к словарю 'ФАМИЛИЯ', если в результате ее морфологического анализа есть тэг 'Surn' (принятое обозначение распознанной фамилии в пакете pymorphy2).
3) Создать экземпляр класса
    Gram = Grammar()
и указать правила грамматики:
3.1) правила замены словарей:
    Gram.add_repl([u'ИМЯ', u'НАЧИНАЕТСЯ_С_ЗАГЛАВНОЙ'], u'ИМЯ')
в данном примере указано правило: если сущность одновременно принадлежит к словарям 'ИМЯ' и 'НАЧИНАЕТСЯ_С_ЗАГЛАВНОЙ', то оставить нужно лишь словарь 'ИМЯ' (в даном случае 'НАЧИНАЕТСЯ_С_ЗАГЛАВНОЙ' является избыточной информацией)
3.2) затем задаются правила объединения сущностей
    Gram.add_seq([u'ИМЯ', u'ОТЧЕСТВО', u'ФАМИЛИЯ'], u'ЧЕЛОВЕК')
    Gram.add_seq([u'ИМЯ', u'ФАМИЛИЯ'], u'ЧЕЛОВЕК')
в первом правиле предписывается для последовательности из трех подряд идущих сущностей, принадлежащих к соответствующим классам ('ИМЯ', 'ОТЧЕСТВО', 'ФАМИЛИЯ') создать новую суперсущность, принадлежащую к словарю (классу) 'ЧЕЛОВЕК', а исходные сущности начать рассматривать как "детей" суперсущности.
3.3) затем задаются правила для связи сущностей (не обязательно идующих подряд):
    Gram.add_link([u'ЧЕЛОВЕК', u'ДЕЙСТВИЕ_ИЗМЕНЕНИЯ', u'ФИРМА'], u'Человек взаимодействует с фирмой')
в данном примере создается связь вида: если в тексте (в пределах одного предложения) следуют последовательно (но не обязательно подряд) сущности из словарей 'ЧЕЛОВЕК' (например, Иван Иванович), 'ДЕЙСТВИЕ_ИЗМЕНЕНИЯ' (например, "покинул") и 'ФИРМА' (например, "ООО АНКОР"), то для таких сущностей следует создать связь типа 'Человек взаимодействует с фирмой'.
4) Затем мы создаем экземпляр основного класса
    TA = TextAnalyzer(Dict, Gram)
передавая его конструктору созданные ранее словарь и грамматику.
5) Далее мы задаем переменную с текстом для анализа, например:
    txt = u'''Кушает ложкой Пётр Сергеевич Иванов.''' 
6) Запустить анализ текста в автоматическом режиме:
    TA.analyze(txt)
7) Вывести полученный результат:
    print TA
8) Результаты анализа могут быть использованы для получения информации по интересуемым словам, например:
    TA.get_info(u'Иван')
выдаст информацию по соответствующей сущности (в случае наличия) и связям, в которых она принимает участие.
    


                    Программа TextAnalyzer: описание алгоритмов и программной реализации.
 
    Опишем разработанный алгоритм извлечения ключевых понятий из текста и соответствующее программное исполнение (программа TextAnalyzer).

    Класс TextAnalyzer является основным инструментом для проведения анализа текста. При инициализации экземпляра класса, конструктору должен быть передан анализируемый текст в виде строки. Анализируемый текст разбивается на сущности, и каждой сущности в программе ставится в соответствие экземпляр класса Entity (Сущность). При этом, любая сущность в программе может или явно соответствовать слову текста - простая сущность (например, слову "Иван" соответствует простая сущность типа "Имя"), либо являться объединением нескольких простых сущностей - суперсущность (например, трем простым сущностям "Иван" и "Сергеевич" и "Иванов", идущим подряд без знаков препинания, может быть поставлена в соответствие одна суперсущность "Человек", причем исходные три сущности сохраняются как дочерние для суперсущности). Отметим, что суперсущность может иметь и только одну дочернюю сущность (например, если для простой сущности "Иван" мы делаем уточнение понятия, вводя суперсущность "Человек").

    Для хранения сущностей используется класс Entity. Экземпляр класса Entity имеет следующие свойства (переменные):
1) word - текст простой сущности, причем нами делается допущение, что это словарное слово (свойство имеет смысл только для простых сущностей);
2) nfrm - нормальная форма слова сущности (свойство имеет смысл только для простых сущностей);
3) wtag - экземпляр класса OpencorporaTag (из пакета pymorphy2), содержащий обнаруженные морфологические характеристики слова сущности (свойство имеет смысл только для простых сущностей);
4) etag - строка, задающая тэг для типа сущности, например "Имя" или "Человек" (полный список возможных значений будет приведен ниже);
5) begs - первый символ слова/текста сущности до удаления знаков пунктуации (для суперсущности берется соответствующее значение begs для первой дочерней сущности);
6) ends - последний символ сущности до удаления знаков пунктуации (для суперсущности берется соответствующее значение ends для последней дочерней сущности);
7) wlen - длина слова сущности (для суперсущности берется сумма значений wlen дочерних сущностей);
8) Children - список дочерних сущностей (пустой список для простых сущностей);
9) ssen - индикатор длясущности, являющейся началом предложения.
Основные методы (функции) класса Entity:
1) __init__(word=None) - конструктор класса с необязательным аргументом - текстом сущности;
2) prepare(morph=None) - функция с необязательным аргументом - экземпляром класса MorphAnalyzer (из пакета pymorphy2) (Прим.: при анализе нескольких сущностей следует использовать один экземпляр данного класса, т.к. при своей инициализации он каждый раз подгружает словари в оперативную память), осуществляет предварительную обработку сущности (если задан текст сущности в переменной word): 
а) очистку от знаков переноса строки и табуляции; 
б) сохранение первого и последнего символов слова сущности в переменные begs и ends для упрощения последующего анализа (это позволяет, например, сохранить завершающую точку в конце сокращения имени или отчества человека, кавычки в названии организации и т.д.);
в) удаление знаков препинания (точки, запятые, кавычки, двоеточия, лишние пробелы) и сохранение очищенного слова в нижнем регистре в переменную word, а его длины в переменную wlen;
г) морфологический анализ слова сущности средствами пакета pymorphy2 (морфологические характеристики сохраняются в переменную wtag, а нормальная форма слова в нижнем регистре в переменную nfrm);
3) child_append(Ent) - функция с аргументом экземпляром класса Entity, добавляющая (в список Children) дочерную сущность к текущей суперсущности, при этом автоматически проводятся необходимые изменения в begs, ends, wlen.
4) __unicode__(), __str__() - стандартные вспомогательные функции для строкового отображения экземпляра класса (вызывается, например, при применении метода print к экземпляру класса). В нашем случае функция возвращает строку, содержащую исходное слово, нормальную форму слова, список морфологических тегов слова, тег сущности (при наличии), а также дополнительные строки (с бОльшим отступом) для вложенных сущностей, при их наличии.

    Экземпляр класса Dictionary позволяет задавать словари, как было указано ранее. Используя сформированный набор словарей, можно проводить идентификацию сущностей с помощью метода Dictionary.define(Entity). Данный метод возвращает список словарей, к которым принадлежит заданная сущность. При наличии интернет-соединения и предварительной настройке посредством метода Dictionary.set_syn_api(...) при идентификации сущностей используется Яндекс-API для выявления синонимов слова сущности, что позволяет производить более гибкий анализ.

    Экземпляр класса Grammar позволяет задавать словари, а также имеет набор методов для выявления последовательной сущностей, удовлетворяющих заданным правилам (более подробно интерфейс был описан в предыдущем разделе).
    
    Небольшой класс Link хранит данные о выявленных связях сущностей, а экземпляр основного класса TextAnalyzer предоставляет интерфейс для анализа текста. Процедура извлечения ключевых понятий из текста разбивается на несколько промежуточных этапов (При вызове функции analyze все этапы работы проходят в автоматическом режиме), каждый из которых осуществляется с помощью соответствующей функции.
1) prepare - первичная разбивка текста на сущности по наличию пробела между словами и предварительная обработка всех сущностей (метод Entity.prepare, описанный выше);
2) compose - редактировании списков словарей для сущностей (удаление лишних словарей) в соответствии с правилами грамматики, заданными посредством Gram.add_repl
3) combine - объединение сущностей в суперсущности в соответствии с правилами грамматики, заданными посредством Gram.add_seq (данный метод следует вызывать несколько раз для получения максимальных уровней вложенности сущностей),
4) parse_links - выявление связей между сущностями.

    После проведения анализа текста становятся доступными команда
    print TA,
которая выводит результаты анализа в текстовой форме и функция
    get_info(word)
которая проводит анализ заданного слова в соответствии с полученными сущностями и их взаимозависимостями (находит соответствующую для данного слова сущность в тексте и выводит ее текстовое описание, а также описание связей, в которых она принимает участие).

                    Тестовые примеры.
                    
    Для тестирования программы были подготовлены необходимый словарь и набор правил грамматики (используется минимальный набор правил, достаточных для анализа простейших текстов, однако, данный набор правил может быть расширен при необходимости решения более сложных прикладных задач) и рассмотрены три модельных текста:
1) Пётр Сергеевич Иванов покинул должность вице-президента  известной фирмы ООО "Анкор". Его заменил Иван Алексеевич Сидоров.
2) У Ивана Петрова есть сын. Марья Петрова его жена.
3) У Кузи есть машина. Машина очень быстрая.

Правила грамматики и результаты анализа приводятся в Приложении к работе. Отметим, что согласно полученным результатам, разработанная программа способна выявлять основные сущности в тексте, осуществлять их контактенацию и производить выявление простейших связей.   
                    
                    Заключение.
                    
    Предложенный в данной работе программный продукт позволяет осуществлять анализ смыслов в текстах, проводить идентификацию сущностей и выявлять взаимозависимости между сущностями. Область текстов доступных для анализа определяется набором правил (эвристик), прописанных в программе. Увеличение числа заданных правил позволит расширить возможности программы.
    
    Отметим, что тема интеллектуального анализа текстов, в частности, выявления смыслов, является чрезвычайно актуальной на сегодняшний день, например, ввиду потребности поисковых систем (таких как Яндекс и Google) в корректной обработке поисковых запросов и интеллектуальном формировании поисковой выдачи и существует широкий спектр программных продуктов для анализа текстов (см., например, приведенные списки в [7, 8], а также описания мощных программ [9, 10, 11]). Однако, ни одна из существующих программ не способна в полной разрешить проблему анализа текстов.
    
    Разработанная в данной работе программа является лишь первым приближением к задаче интеллектуального анализа текстов, и для ее развития необходима реализация ряда современных подходов к анализу, например, использование в явном виде контекстно-свободных грамматик [12], проведение анализа онтологий [13] и т.д.


                    Литература

[1] https://www.python.org/
[2] https://pythonhosted.org/spyder/
[3] https://ipython.org/notebook.html
[4] https://www.continuum.io
[5] https://media.readthedocs.org/pdf/pymorphy2/0.4/pymorphy2.pdf
[6] http://opencorpora.org/dict.php?act=gram
[7] http://morphs.ru/posts/23
[8] https://nlpub.ru/%D0%9E%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0
[9] https://tech.yandex.ru/tomita/doc/dg/concept/example-docpage/
[10] http://vas3k.ru/blog/358/
[11] https://github.com/vas3k/python-glr-parser
[12] https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BD%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BD%D0%BE-%D1%81%D0%B2%D0%BE%D0%B1%D0%BE%D0%B4%D0%BD%D0%B0%D1%8F_%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0
[13] https://habrahabr.ru/company/yandex/blog/205198/ онтологии